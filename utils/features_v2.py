import time
import os
import pickle
import numpy as np
from collections import OrderedDict
from collections import namedtuple
from random import shuffle
import copy
from itertools import combinations, combinations_with_replacement
from utils.utils import ROOT, dep_sample_generator
from typing import List, Dict
from utils.utils import DepSample


def generate_features_dict(path_to_file, sample2features, start_idx, feature_threshold=0, save_to_file=False,
                           features_name=''):
    """
    This function generates a features dictionary, such that for every features, an index is given starting from start
    the given start_idx.
    The following features are generated for a given dataset:
    byt the given sample2features which is a lambda exprestion to extract a feature from a sample
    you can think of sample2features as a template
    :param: path_to_file: path to location of the dataset (str)
    :param: feature_threshold: if to consider a feature with word that appears less than that in the dataset (int)
    :param: save_to_file: whether or not to save the dictionary on the disk (bool)
    :param: word_hist: dictionary of words histogram in the dataset (dict)
    :return: hw_hp_feat_dict: dictionary feature->index (dict)
    """

    samp_gen = dep_sample_generator(path_to_file)
    hw_hp_feat_dict = OrderedDict()
    features_hist = OrderedDict()

    for s_i, sample in enumerate(samp_gen):
        for s in sample:
            # ignore ROOT
            if s.token == ROOT:
                continue

            feats = sample2features(sample, s)
            for feat in feats:
                features_hist[feat] = features_hist.get(feat, 0) + 1

    current_idx = start_idx
    for k, v in features_hist.items():
        if v > feature_threshold:
            hw_hp_feat_dict[k] = current_idx
            current_idx += 1

    # print("total {:} features: ".format(features_name), current_idx)
    hw_hp_feat_dict = OrderedDict(sorted(hw_hp_feat_dict.items(), key=lambda t: t[1]))
    if save_to_file:
        path = path_to_file + features_name + '.dict'
        with open(path, 'wb') as fp:
            pickle.dump(hw_hp_feat_dict, fp)
        print("saved {:} features dictionary @ ".format(features_name), path)
    return hw_hp_feat_dict


def generate_features_dicts(path_to_file: str, save_to_file: bool =False, minimal: bool=False)->Dict[str, dict]:
    """
    given a training file we return a dictionary of dictionaries
    where key is feature type name, and value is a dictionary of that feature generated by 'generate_features_dict'
    according to feature templates required by hw2 pg 2, those templates are:
    head word _ head pos
    head word
    head pos
    child word _ child pos
    child word
    child pos
    h_pos c_word c_pos

    if not minimal we add:
        h_word h_pos c_word c_pos
        h_word c_word c_pos
        h_word h_pos c_word
        h_word c_word'
    :param path_to_file: training file to extract features from
    :param save_to_file: if to save the dictionary
    :param minimal: if to add the extra features as described
    :return: dictionary described above
    """

    feature_types = {'head word _ head pos': (lambda sample, s: [(sample[s.head].token, sample[s.head].pos)], 0),
                     'head word': (lambda sample, s: [(sample[s.head].token)], 0),
                     'head pos': (lambda sample, s: [(sample[s.head].pos)], 0),
                     'child word _ child pos': (lambda sample, s: [(s.token, s.pos)], 0),
                     'child word': (lambda sample, s: [(s.token)], 0),
                     'child pos': (lambda sample, s: [(s.pos)], 0),
                     'h_pos c_word c_pos': (lambda sample, s: [(sample[s.head].pos, s.token, s.pos)], 0),
                     'h_word h_pos c_pos': (lambda sample, s: [(sample[s.head].token, sample[s.head].pos, s.pos)], 0),
                     'h_pos c_pos': (lambda sample, s: [(sample[s.head].pos, s.pos)], 0),
                     }

    if not minimal:

        feature_types['h_word h_pos c_word c_pos'] = (lambda sample, s:
                                                      [(sample[s.head].token, sample[s.head].pos, s.token, s.pos)], 2)

        feature_types['h_word c_word c_pos'] = (lambda sample, s:
                                                [(sample[s.head].token, s.token, s.pos)], 2)

        feature_types['h_word h_pos c_word'] = (lambda sample, s:
                                                [(sample[s.head].token, sample[s.head].pos, s.token)], 2)

        feature_types['h_word c_word'] = (lambda sample, s:
                                          [(sample[s.head].token, s.token)], 2)

    features_dicts = {}
    current_num_features = 0
    for feature_type_name, (feature_template, feature_threshold) in feature_types.items():

        features_dicts[feature_type_name] = generate_features_dict(path_to_file,
                                                                   feature_template,
                                                                   start_idx=current_num_features,
                                                                   feature_threshold=feature_threshold,
                                                                   save_to_file=False,
                                                                   features_name=feature_type_name)

        num_features = len(features_dicts[feature_type_name])
        current_num_features += num_features

        print('generated {:} features , num features{:} , total num_features {:}'.format(feature_type_name,
                                                                                         num_features,
                                                                                         current_num_features))

    return features_dicts


def extract_local_feature_indices(head: DepSample, child: DepSample, dictionaries: Dict[str, OrderedDict], minimal:bool):
    """
    returns a list of indices that turned on given the head location
    :param head: head DepSAmple
    :param child: child/ current DepSample
    :param dictionaries:  dictionaries of features as generated by 'generate_features_dicts'
    :param minimal: if we're operating on minimal or full model
    :return: list of features that turned on on the given head and  child
    """

    dictionary_names = [
        'head word _ head pos',
        'head word',
        'head pos',
        'child word _ child pos',
        'child word',
        'child pos',
        'h_pos c_word c_pos',
        'h_word h_pos c_pos',
        'h_pos c_pos',
        'h_word h_pos c_word c_pos',
        'h_word c_word c_pos',
        'h_word h_pos c_word',
        'h_word c_word']

    feature_ind = []
    idx = dictionaries['head word _ head pos'].get((head.token, head.pos))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['head word'].get((head.token))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['head pos'].get((head.pos))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['child word _ child pos'].get((child.token, child.pos))
    if idx is not None:
        feature_ind.append(idx)

        idx = dictionaries['child word'].get((child.token))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['child pos'].get((child.pos))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['h_pos c_word c_pos'].get((head.pos, child.token,child.pos))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['h_word h_pos c_pos'].get((head.token, head.pos, child.pos))
    if idx is not None:
        feature_ind.append(idx)

    idx = dictionaries['h_pos c_pos'].get((head.pos, child.pos))
    if idx is not None:
        feature_ind.append(idx)

    if not minimal:
        # [h_word h_pos c_word c_pos,
        # 'h_word c_word c_pos',
        # 'h_word h_pos c_word',
        # 'h_word c_word']

        idx = dictionaries['h_word h_pos c_word c_pos'].get((head.token, head.pos, child.token, child.pos))
        if idx is not None:
            feature_ind.append(idx)

        idx = dictionaries['h_word c_word c_pos'].get((head.token, child.token, child.pos))
        if idx is not None:
            feature_ind.append(idx)

        idx = dictionaries['h_word h_pos c_word'].get((head.token, head.pos, child.token))
        if idx is not None:
            feature_ind.append(idx)

        idx = dictionaries['h_word c_word'].get((head.token, child.token))
        if idx is not None:
            feature_ind.append(idx)

        return feature_ind


def extract_global_features(sample: List[DepSample], dictionaries: Dict[str, OrderedDict], minimal: bool)\
        ->Dict[int, int]:
    """
    given a sample we return a dictionary where keys are features that turned on
    and values are how manny times they turned on
    :param sample: list of DepSample to return features of
    :param dictionaries: of features generated by 'generate_features_dicts'
    :param minimal: if the model is with minimal features
    :return: dict
    """

    features_counters = {}

    for s in sample:

        if s.token == ROOT:
            continue

        feature_ind = extract_local_feature_indices(sample[s.head], s, dictionaries, minimal)
        for feat in feature_ind:
            features_counters[feat] = features_counters.get(feat, 0) + 1

    return features_counters

